\section{Background}\label{sec:background}
As the line between system management and system orchestration is becoming thinner, configuration management tools are likely to be used for some orchestration purposes \cite{papazoglou2003service}. Additionally, all configuration management systems (CMS) are using either a push or a pull system to inform clients in case of updates. Lastly, \texttt{mgmt} is a new system which challenges the architectural model of established configuration management tools. This section presents a brief comparison of the selected configuration management tools and the distributed \texttt{mgmt}.

%added a citation about orchestration and SOA. Don't know if it is really related. But in a far distance it empowers the first line of this section.

\begin{lstlisting}[caption={Shellshock security patching with Ansible playbook},label=lst:shellshock]
- hosts: all
  gather_facts: yes
  remote_user: administrator
  sudo: yes
  tasks:
    - name: Update Shellshock (Debian)
      apt: name=bash
           state=latest
           update_cache=yes
      when: ansible_os_family == "Debian"
 
    - name: Update Shellshock (RedHat)
      yum: name=bash
           state=latest
           update_cache=yes
      when: ansible_os_family == "RedHat"
\end{lstlisting}

\subsection{Migration strategies}\label{subsec:migrationstrategies}
Migrating between systems can be done in different strategies and using different tooling, when using Configuration management system (CMS) A on all of the servers. New servers can be managed by CMS B. This will result in a slow migration between the management systems. The lifetime of a server dictates the time it will take to migrate, nowadays only the low level systems like NTP, DNS and authentication server should be bare metal servers. All other services depending on these could be virtual. The lifetime of these virtual servers is often less than the lifetime of bare metal machines because the virtual machines are created to support a specific service and are terminated directly when the service is no longer needed. Some special cases are excluded from this example, for instance a DHCP servers. When using virtual machines the migration process can be finished fast. In a cluster of 10 webservers managed by CMS A offering the same website, a new webserver could be created managed by CMS B. When tested and approved it can be added to the cluster. An old server should be removed from the cluster and decommissioned. In Large scale environments this will be an extensive job. Try doing this in a farm of a hundred web front-end servers.

\begin{quote}
According to Jaap van Ginkel on thursday 10-3-2016 during a lecture on Large Installation Administration, "More system administrators scale out services by using virtual machines"
\end{quote}

To keep server management easy and effective. One configuration management system should be used and the migration should not stretch multiple years. A Big bang scenario is a proper alternative. Migrating all the webservers from CMS A to CMS B by a set of automated steps without installing new servers. Therefore not using extra resources and migrating without downtime. This big bang scenario \cite{bigbang} is explained in this report as the focus of this report lays on Large Installation Administration.


\subsection{Orchestration and configuration management}\label{subsec:orchestration}
In this report we repeatedly discuss configuration management. As this term carries a somewhat ambiguous definition, we settle on the definition as presented by Pieter Lexis during a guest lecture at the University of Amsterdam. He defines configuration management as "the techniques and policies to track hardware, infrastructure and software, and the configuration thereof". During the course of this report we will use this definition exclusively.


\subsection{Differences between Push and Pull based management systems}\label{subsec:pushpull}
Puppet and Chef are pull based CMS's. A clients needs to be installed on the managed machine. This clients checks in at the server every x minutes. For puppet the default x time is 30 minutes. So every 30 minutes the configuration as it should be according to puppet is compared to the current configuration of the server. The puppet configuration can make sure a specific version of apache is installed or if a website contains a certain line of text. When the configuration differs from the configuration set in the Puppet configuration it will be changed immediately. Where Ansible and Salt use the push technique to send commands to a managed machine. Ansible uses playbook which hold the command set for specific server and it contains the destinations for the command set. The management server starts communication over SSH to the management machines and delivers and runs a python script on the client. So Python is a prerequisite for Ansible. The Python script is removed right after it is executed. This way of configuring servers is on demand. But as Puppet it is able to check for specific software versions or check file content and change it if needed. When a configuration differs from the configuration in the playbook. The client will be changed when the playbook is run by an administrator. So when a playbook is not run, the configuration could differ from the intended configuration for a long time. 

When a CMS only needs SSH to remote configure a machine, the scale of systems it could manage is a lot bigger than a client based system. If the system to manage has a closed operating system it cant be managed by a pull based CMS. All large networking brands make sure there operating systems (OS) are able to keep running for years without interruption. To make sure the system stays up the OS is closed down making sure no third party applications are able to disrupt the system. Push based systems only rely on a SSH connection. Ansible is capable of executing the python script on the server, therefore the requirement of python on the managed server is no longer there. This makes it possible to manage closed source network operating systems like Juniper or Cisco devices run. 

A router or switch could be set up with the necessary basics to make sure it can be placed at the designated location and is accessible over the network by SSH. Ansible can be set up to do the rest of the configuration. Running a playbook that will generate a base configuration for all the machines within the same class and check the running configuration to see if it matches. If it doesn't match. Ansible will change it. Next to configuration changes, depending on the brand of equipment, Ansible is capable of performing a code upgrade on network devices. Some of the new devices offer nonstop service upgrades \cite{NSSU}\cite{ISSU}, what actually means upgrading the system during office hours without any downtime (when everything is configured in a proper way and all requirements are matched). When the installed base of a specific brand and type is big enough automation of configuration or code changes have as much advantages on network devices as it has on server configuration.  

\subsection{Distributed configuration management}\label{subsec:distributedmgmt}
As previously alluded to, a relatively new configuration management tool on the horizon is \texttt{mgmt}. \texttt{Mgmt} is currently classified as a 'prototype next generation configuration management tool' and is developed by Shubin \cite{shubin2016}. The tool focuses on \textit{parallelization}, \textit{event driven changes} and most notably, a \textit{distributed architecture} \footnote{The source code for \texttt{mgmt} is available on GitHub: \url{https://github.com/purpleidea/mgmt/}}. 

\subsubsection{Distribution}
The main point of innovation in \texttt{mgmt} is the distributed topology of the system. As discussed in section \ref{subsec:pushpull}, traditional tools like Ansible and Puppet generally run in a client-server, push or pull manner. Naturally, as all code is placed in a central location, scalability and performance issues occur, especially when the amount of clients increases. Additionally, Shubin argues that using a client-server model reduces the configuration management tool to a single failure domain. Clustering of the master server could alleviate this problem, however, this would take away from the simplicity of a centralized system. Ansible on the other hand uses an orchestration model in which a push model is used. One of the most overlooked features in Puppet is the puppet executable. This allows you to both compile and apply catalogs locally, removing the complexity of running in client/server mode. However, as Shubin notes, this is a glorified method of running local scripts. Some users have opted not to use the Puppet master at all for scaling reasons. Although we feel that we have addressed most of these scaling issues with performance improvements in .25.x, the PuppetMaster will always be the bottleneck in client/server mode. For this deployment practice, users compile catalogs and apply configuration changes locally with the puppet executable. Code on all of the hosts is then kept in sync with a central repository using something like rsync. This will always be the best way to scale Puppet deployments, but it suffers from a loss in security as well as ease of management. This introduces new questions. With no puppetmasters, you have to allow *every* server to connect to your database instance. Another option would be to use a tiered Puppet Master system in which areas are defined. The top tier master would maintain other Puppet masters which in turn configure a set of clients. Similarly, Ansible can run in a local mode by specifiying the target to be the local machine. 

\subsubsection{Parallelization}
However, providing the option for parallel execution introduces room for errors as well. In a simple example, running two package installations with \texttt{apt} in parallel would fail due to a global lock on \texttt{dpkg}. Similarly, dependencies between applications and libraries would have to be resolved in a sequential manner. \texttt{Mgmt} deals with this scenario by batching (or grouping) all blocking operations and putting them in a sequential order. All operations which can be parallelized are placed in disjoint graphs as opposed to a directed acyclic graph. Parallelization does allow a system to reach its end state more rapidly. Long running processes which limited the deployment speed in a sequential process can now be converge quicker. In the setup for our experiment, the modules have direct dependencies. However, in a real world scenario it isn't uncommon for a company to have multiple disconnected modules without inter-dependencies run simultaneously. Tradeoff between safety and speed. 

%add images for parallel operations

\subsubsection{Event based model}
All the discussed configuration management systems have a notion of idempotence. In practice this means that the tools check the state of a certain element and compare it to a desired end state. If the state at time of checking has diverged from the desired state, the configuration will be altered by either a pull (Puppet) or push (Ansible) operation. In the context of Puppet this check operation is executed every 30 minutes by default. Ansible's push operation has to be manually scheduled with a \texttt{cronjob}. This mode of operation allows a configuration to diverge during the timeframe in which no check operation is performed. Naturally, a more preferable method would be to define an end state 

\subsubsection{Migration possibilities}
Another advantage which \texttt{mgmt} poses is that a migration between a tool like Puppet the tools could potentially be fairly easy. Converting Puppet modules to \texttt{mgmt} graphs is a straight forward process as displayed by ffrank \cite{}. However, due to the fact that \texttt{mgmt} still uses an experimental DSL, conversions at this point are mood. This is also exhibited by Frank \cite{}. 
